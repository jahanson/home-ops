apiVersion: v1
kind: Pod
metadata:
  name: build-trt-models
  namespace: default
spec:
  containers:
    - name: tensorrt
      image: nvcr.io/nvidia/tensorrt:23.06-py3@sha256:afc0c671c08c9366ab333e640cd31cffb9bbd1faf3dc31214561a243dea0a9cf
      # command: ["/bin/bash", "-c", "/trt_models/build_trt.sh"]
      command: ["/bin/bash", "-c", "while true; do sleep 10; done"]
      resources:
        requests:
          nvidia.com/gpu: "1"
          cpu: 323m
          memory: 443M
        limits:
          nvidia.com/gpu: "1"
      volumeMounts:
        - mountPath: /tensorrt_models
          name: trt-models
  runtimeClassName: nvidia
  nodeSelector:
    feature.node.kubernetes.io/pci-0300_10de.present: "true"
    kubernetes.io/hostname: "glamdring" # until I can figure out how to blacklist the old GPU.
  volumes:
    - name: trt-models
      nfs:
        server: "nas.jahanson.tech"
        path: /volume1/trt-models/nvidia-2060
